************************************************************
OPT++ version 2.4
Job run at Wed Oct 26 12:52:20 2016

Copyright (c) 2001, Sandia Corporation.  Under the terms of Contract
DE-AC04-94AL85000, there is a non-exclusive license for use of this
work by or on behalf of the U.S. Government.  Export of this program 
may require a license from the United States Government. 

This software is distributed under the GNU Lesser General Public License. 

For more information, see the COPYRIGHT and README files in the top 
OPT++ directory.
************************************************************

				Nonlinear CG
  Iter      F(x)       ||grad||    ||step||     beta       gtp        fcn

    0         24.2        232.9
    1        9.733        116.3      0.0836            0   -2.707e+04   7    7
    2        5.627        58.12     0.04734            0        -6759  13   13
    3        4.519        29.07     0.02549            0        -1689  19   19
    4        4.229        14.56     0.01331            0       -422.5  24   24
    5        4.154        7.331    0.006889            0         -106  29   29
    6        4.134        3.777    0.003672            0       -26.87  33   33
    7        4.127        2.138      0.0023            0       -7.131  37   37
    8        4.122        1.915    0.003275       0.3023       -2.286  41   41
    9        4.055        9.689      0.0634        26.64      -0.5239  43   43
   10        3.643        19.11      0.3253        1.939          -32  47   47
   11        2.633        16.37      0.5506            0        2.403  53   53
   12        2.406        8.242     0.01855            0       -134.1  58   58
   13        2.343        4.254     0.01017            0       -33.96  63   63
   14        2.322        2.444    0.006644            0       -9.048  67   67
   15        2.301        2.441     0.01174       0.4986       -2.982  71   71
   16        2.159        7.073     0.09722        9.168       -1.413  74   74
   17         1.92        10.26      0.1635       0.6949       -17.87  78   78
   18        1.233        3.161      0.2459            0       -45.97  82   82
   19        1.199        2.154     0.01431            0       -4.994  86   86
   20       0.8923        6.805       0.216        10.36        1.755  90   90
   21       0.8509        8.599     0.06284       0.3554       0.7456  96   96
   22        0.671        3.699     0.03842            0       -36.82 101  101
   23       0.6448        2.017    0.009464            0        -6.84 104  104
   24       0.6306        1.472    0.009349      0.03232       -2.035 107  107
   25       0.5104         3.64      0.1083        5.885      -0.6895 110  110
   26       0.3199       0.8907      0.1678      0.01082       -8.579 114  114
   27       0.3062         2.51     0.02659        7.925     -0.09217 117  117
   28       0.2253        5.698       0.158        3.011      -0.2532 124  124
   29       0.1407       0.9881     0.09814            0       -13.85 129  129
   30       0.1398       0.5601    0.001229            0      -0.4882 132  132
   31       0.1391       0.5017    0.001749       0.3023      -0.1569 135  135
   32       0.1313          2.5     0.03013        25.97    0.0006995 139  139
   33       0.1088        4.548     0.08734        1.507       -1.503 143  143
   34      0.07822        1.346     0.04466            0       -11.44 148  148
   35      0.07706       0.6922    0.001144            0      -0.9059 151  151
   36       0.0767       0.3885   0.0007022            0      -0.2396 154  154
   37      0.07635       0.4478    0.001503        1.158     -0.02566 158  158
   38      0.06691        2.724     0.05114        40.99      0.00195 162  162
   39      0.05001        4.543      0.1079        1.121      -0.6769 168  168
   40       0.0307          1.7     0.03863            0       -10.69 174  174
   41      0.02925       0.8545    0.001136            0       -1.445 177  177
   42      0.02887       0.4365   0.0005907            0      -0.3651 180  180
   43      0.02876       0.2381   0.0003446            0     -0.09527 183  183
   44      0.02868       0.2168   0.0005672       0.6588    -0.009639 187  187
   45      0.02574        1.492     0.02624        50.88    -0.009767 189  189
   46     0.008936        1.747      0.1441        0.205      -0.7394 193  193
   47     0.006944       0.1919    0.003782            0      -0.5444 197  197
   48     0.006925       0.1055   0.0001325            0     -0.01842 200  200
   49     0.006911       0.1022   0.0002325       0.7689     -0.00189 204  204
   50     0.006333       0.7701     0.01189        60.96    -0.001636 206  206
   51      0.00138        1.064      0.1058       0.5323      -0.1013 210  210
   52    0.0008393       0.4791    0.002884            0      -0.5925 213  213
   53    0.0007494       0.2399   0.0002502            0      -0.1148 216  216
   54    0.0007267       0.1206   0.0001263            0     -0.02877 219  219
   55    0.0007208      0.06156   6.553e-05            0    -0.007267 222  222
   56    0.0007185      0.02449   6.328e-05            0   -0.0006439 226  226
   57    0.0005524       0.2749    0.009099        125.5   -0.0002998 228  228
   58    0.0003748       0.2489    0.009121        1.715    -0.005757 233  233
   59    0.0002444       0.4961     0.01679        1.983    -0.008848 237  237
   60     7.03e-05       0.2232     0.00936            0      -0.1318 243  243
   61    5.143e-05       0.1117   0.0001127            0     -0.02492 246  246
   62     4.67e-05      0.05591    5.65e-05            0    -0.006234 249  249
   63     4.55e-05      0.02812   2.854e-05            0    -0.001563 252  252
   64    4.519e-05       0.0144   1.487e-05            0   -0.0003954 255  255
   65    4.507e-05     0.006033   1.463e-05     0.005627   -3.523e-05 259  259
   66    2.772e-06      0.04491     0.01201        55.36   -5.889e-06 263  263
   67    1.698e-06       0.0185   0.0002076            0    -0.001172 266  266
   68    1.569e-06     0.009268   9.287e-06            0   -0.0001712 269  269
   69    1.527e-06     0.001826   7.806e-06            0    -1.46e-05 273  273
checkConvg: deltaf =    2.555e-09  ftol =     1.49e-08
   70    1.524e-06     0.001192   2.392e-06


=========  Solution from CG: Fcn not Expensive  ===========

Optimization method       = Nonlinear CG
Dimension of the problem  = 2
Return code               = 2 (OptCG: Algorithm converged)
No. iterations taken      = 70
No. function evaluations  = 277
No. gradient evaluations  = 277


==========  Tolerances  ===========

Machine Epsilon      = 2.22045e-16
Maximum Step         = 1000
Minimum Step         = 1.49012e-08
Maximum Iter         = 100
Maximum Backtracks   = 10
Maximum Fcn Eval     = 1000
Step Tolerance       = 1.49012e-08
Function Tolerance   = 1.49012e-08
Constraint Tolerance = 1.49012e-08
Gradient Tolerance   = 1e-06
LineSearch Tolerance = 0.0001


=========  Solution from CG: Fcn not Expensive  ===========


    i	    xc 		 grad  		 fcn_accrcy 
     1      0.9988	  -0.0008956	    2.22e-16
     2      0.9975	  -0.0007871	    2.22e-16
Function Value     =    1.524e-06
Norm of gradient   =     0.001192


==============================================

************************************************************
OPT++ version 2.4
Job run at Wed Oct 26 12:52:20 2016

Copyright (c) 2001, Sandia Corporation.  Under the terms of Contract
DE-AC04-94AL85000, there is a non-exclusive license for use of this
work by or on behalf of the U.S. Government.  Export of this program 
may require a license from the United States Government. 

This software is distributed under the GNU Lesser General Public License. 

For more information, see the COPYRIGHT and README files in the top 
OPT++ directory.
************************************************************

				Nonlinear CG
  Iter      F(x)       ||grad||    ||step||     beta       gtp        fcn

    0         24.2        232.9
    1        4.674        34.57      0.1515            0        -8049   9    2
    2        4.255        16.48     0.01646            0         -569  15    3
    3        4.158        8.155    0.007885            0       -133.6  21    4
    4        4.133        4.156    0.004056            0       -33.08  27    5
    5        4.126        2.287    0.002429            0       -8.578  32    6
    6        4.121        1.814    0.002756       0.1318       -2.601  37    7
    7         3.99        9.936      0.1008        30.24       -1.481  40    8
    8        3.082        24.41      0.7618        3.698        122.6  45    9
    9        3.069        24.99     0.03274      0.02477       -48.31  54   10
   10        2.466        7.764     0.03793            0         -199  60   11
   11        2.412        3.965    0.009397            0       -29.63  66   12
   12        2.393        2.304    0.006342            0       -7.665  71   13
   13        2.365        2.993     0.01723        1.235       -2.401  76   14
   14        2.217        6.643     0.09435         6.02       -2.384  80   15
   15        2.003        9.889      0.1457       0.7634       -22.76  86   16
   16        1.218        5.063      0.3212            0       -25.71  91   17
   17        1.144        2.123     0.02531      0.01498       -4.125  95   18
   18        0.945        3.147      0.1077        1.653        -2.69  98   19
   19       0.4919        1.329      0.2805            0       -7.196 101   20
   20       0.4773        1.834     0.01655          1.6       -0.539 105   21
   21        0.209        1.647        0.31      0.05268       -1.326 107   22
   22       0.2061       0.8616     0.00234            0        -1.39 112   23
   23       0.2049       0.6094    0.001957    0.0003033      -0.3712 117   24
   24       0.1704       0.7934     0.06096       0.8577      -0.3112 119   25
   25       0.1679       0.9352    0.005993        1.661      -0.1203 123   26
   26      0.08484        3.794      0.2289        12.76      -0.9103 125   27
   27      0.06056          1.8      0.0538       0.6894        1.398 131   28
   28      0.05988        2.284    0.008191       0.3425       -1.142 138   29
   29      0.05343       0.6307     0.01152            0       -2.769 143   30
   30      0.05316       0.3436   0.0005539            0      -0.1988 148   31
   31      0.05302       0.2511   0.0005435        0.034     -0.05903 153   32
   32      0.04223        1.532     0.05355        36.88     -0.03591 155   33
   33      0.03421        1.231     0.03697        1.412      -0.6891 160   34
   34     0.009483       0.4998      0.1705        0.553       -1.074 165   35
   35     0.003266         1.17     0.09783        7.751      -0.2826 170   36
   36    0.0006859        0.368     0.05521            0       -1.847 178   37
   37    0.0006152      0.02266    0.000384     0.003807    2.242e-06 182   38
   38    0.0002115      0.05275      0.0227        4.714   -0.0002925 183   39
   39     0.000209      0.01651   0.0001079            0    -0.002081 188   40
   40    0.0002087       0.0135   2.255e-05       0.1679   -0.0001364 193   41
   41    0.0002021      0.08112   0.0007675        36.71   -5.767e-05 196   42
   42    0.0001284       0.1221    0.006883        3.727    -0.003637 200   43
   43     6.97e-05      0.04606     0.00602       0.5086     -0.01318 205   44
   44    2.384e-05       0.0493    0.007857        2.182    -0.004068 210   45
   45    2.536e-06      0.02051    0.007214       0.5844    -0.002768 215   46
   46    2.547e-08     0.007126    0.003387            0   -5.038e-05 220   47
   47    6.439e-09     0.003557   3.563e-06            0   -2.535e-05 225   48
checkConvg: deltaf =    4.743e-09  ftol =     1.49e-08
   48    1.697e-09     0.001776   1.779e-06


=========  Solution from CG: Fcn Expensive  ===========

Optimization method       = Nonlinear CG
Dimension of the problem  = 2
Return code               = 2 (OptCG: Algorithm converged)
No. iterations taken      = 48
No. function evaluations  = 230
No. gradient evaluations  = 49


==========  Tolerances  ===========

Machine Epsilon      = 2.22045e-16
Maximum Step         = 1000
Minimum Step         = 1.49012e-08
Maximum Iter         = 100
Maximum Backtracks   = 10
Maximum Fcn Eval     = 1000
Step Tolerance       = 1.49012e-08
Function Tolerance   = 1.49012e-08
Constraint Tolerance = 1.49012e-08
Gradient Tolerance   = 1e-06
LineSearch Tolerance = 0.0001


=========  Solution from CG: Fcn Expensive  ===========


    i	    xc 		 grad  		 fcn_accrcy 
     1           1	    0.001584	    2.22e-16
     2           1	  -0.0008017	    2.22e-16
Function Value     =    1.697e-09
Norm of gradient   =     0.001776


==============================================

